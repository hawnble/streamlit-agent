from langchain.agents import AgentType
from langchain_experimental.agents.agent_toolkits.pandas.base import create_pandas_dataframe_agent
#from langchain.callbacks import StreamlitCallbackHandler
from langchain.callbacks.base import BaseCallbackHandler
from langchain.chat_models import ChatOpenAI
from langchain.schema import AIMessage, HumanMessage, SystemMessage
#from streamlit_chat import message
import torch
import streamlit as st
import pandas as pd
import os

df = pd.read_csv("laptop_sdf_231021.csv")
#df = df.astype(str)
df.pop('Unnamed: 0')
#df

from sentence_transformers import SentenceTransformer
q_df = pd.read_excel("EQC_df_231023.xlsx")

model = SentenceTransformer('jhgan/ko-sroberta-multitask')


file_formats = {
    "csv": pd.read_csv,
    "xls": pd.read_excel,
    "xlsx": pd.read_excel,
    "xlsm": pd.read_excel,
    "xlsb": pd.read_excel,
}




# Submit ë²„íŠ¼ ìƒíƒœë¥¼ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
def clear_submit():
    st.session_state["submit"] = False

# ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. (ìºì‹± ì„¤ì •: 2ì‹œê°„)
# @st.cache_data(ttl="2h")
# def load_data(uploaded_file):
#     try:
#         # íŒŒì¼ í™•ì¥ì ì¶”ì¶œ
#         ext = os.path.splitext(uploaded_file.name)[1][1:].lower()
#     except:
#         ext = uploaded_file.split(".")[-1]

#     # íŒŒì¼ í˜•ì‹ì— ë”°ë¼ ì ì ˆí•œ í•¨ìˆ˜ë¡œ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
#     if ext in file_formats:
#         return file_formats[ext](uploaded_file)
#     else:
#         # ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì¼ ê²½ìš° ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥
#         st.error(f"Unsupported file format: {ext}")
#         return None
def cal_score(a, b):
    a = torch.tensor(a)  # NumPy ë°°ì—´ì„ PyTorch í…ì„œë¡œ ë³€í™˜
    b = torch.tensor(b)  # NumPy ë°°ì—´ì„ PyTorch í…ì„œë¡œ ë³€í™˜
    if len(a.shape) == 1: a = a.unsqueeze(0)
    if len(b.shape) == 1: b = b.unsqueeze(0)
    a_norm = a / a.norm(dim=1)[:, None]
    b_norm = b / b.norm(dim=1)[:, None]
    return torch.mm(a_norm, b_norm.transpose(0, 1)) * 100


class StreamHandler(BaseCallbackHandler):
    def __init__(self, container, initial_text=""):
        self.container = container
        self.text=initial_text
    def on_llm_new_token(self, token: str, **kwargs) -> None:
        # "/" is a marker to show difference
        # you don't need it
        self.text+=token
        self.container.markdown(self.text)

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Pick-Chat! : Chat with DataFrame!", page_icon="ğŸ¦œ")
st.title("ğŸ¦œ Pick-Chat! : Chat with DataFrame!")

# # íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯ì„ ìƒì„±í•©ë‹ˆë‹¤.
# uploaded_file = st.file_uploader(
#     "Upload a Data file",
#     type=list(file_formats.keys()),
#     help="Various File formats are Support",
#     on_change=clear_submit,
# )

# # íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ì„ ë•Œ ê²½ê³  ë©”ì‹œì§€ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
# if not uploaded_file:
#     st.warning(
#         "This app uses LangChain's `PythonAstREPLTool` which is vulnerable to arbitrary code execution. Please use caution in deploying and sharing this app."
#     )

# # íŒŒì¼ì´ ì—…ë¡œë“œëœ ê²½ìš° ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
# if uploaded_file:
#     df = load_data(uploaded_file)

# OpenAI API í‚¤ ì…ë ¥ì„ ë°›ìŠµë‹ˆë‹¤.
#openai_api_key = st.sidebar.text_input("OpenAI API Key", type="password")
openai_api_key = st.secrets["openai_key"]
# ëŒ€í™” ê¸°ë¡ì„ ì´ˆê¸°í™”í•˜ê±°ë‚˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ëŒ€í™” ê¸°ë¡ì„ ì‚­ì œí•©ë‹ˆë‹¤.
if "messages" not in st.session_state :#or st.sidebar.button("Clear conversation history")
    # ì´ˆê¸° ëŒ€í™” ë©”ì‹œì§€ ì„¤ì •
    st.session_state["messages"] = [{"role": "assistant", "content": "ì§ˆë¬¸ì„ ìƒì„¸íˆ ì‘ì„±í•´ ì£¼ì‹œë©´ ì •í™•í•œ ë‹µë³€ì´ ê°€ëŠ¥í•´ìš”!"}]

# ì´ì „ ëŒ€í™” ë‚´ìš©ì„ í‘œì‹œí•©ë‹ˆë‹¤.
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
if prompt := st.chat_input(placeholder="ê°€ë³ê³  ë¹ ë¥¸ ë…¸íŠ¸ë¶ ì¶”ì²œí•´ì¤„ë˜? ë¬´ê²ŒëŠ” 1.5kg ì´í•˜ë©´ ê´œì°®ì„ê±° ê°™ì•„!"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
    max_sim = -1
    max_idx = -1
    user_query = prompt
    for idx, val in q_df[['Embedded_Queries']].iterrows():
        embedded_user_query = model.encode(user_query)
        cos_sim = cal_score(embedded_user_query, q_df.loc[idx, 'Embedded_Queries'])
  
        if cos_sim > max_sim:
            max_sim = cos_sim.item()
            max_idx = idx

    similar_quary = q_df.loc[max_idx, 'Queries']
    code = q_df.loc[max_idx, 'codes']
    prefix_text = f'''ë„ˆëŠ” ë…¸íŠ¸ë¶ì„ ì „ë¬¸ì ìœ¼ë¡œ ì¶”ì²œí•´ì£¼ëŠ” ì±—ë´‡ Pick-Chat!ì´ì•¼.
í•­ìƒ ê°€ê²©ê³¼ ë¬´ê²Œì™€ í™”ë©´í¬ê¸°ì™€ ì¥ì ì„ ë§í•´ì¤˜. ë‹¤ë¥¸ ì •ë³´ëŠ” ìš”ì²­ì‹œì—ë§Œ ì œê³µí•´.
ì„œë¡œë‹¤ë¥¸ì œì¡°ì‚¬ë¡œ ì œí’ˆì„ ìµœëŒ€ 5ê°œ ì¶”ì²œí•˜ê³  ì œí’ˆë§ˆë‹¤ ì¤„ë°”ê¿ˆì„ í•´ì¤˜.
ì§ˆë¬¸ì— ë¶€í•©í•˜ëŠ” ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°ì—ëŠ” ì‚¬ìš©ìì—ê²Œ ì§ˆë¬¸ì„ ë” ìì„¸íˆ ì‘ì„±í•´ë‹¬ë¼ê³  ìš”ì²­í•´.
í•­ìƒ í•œê¸€ë¡œ ë‹µë³€ì„ ì‘ì„±í•´. ì ˆëŒ€ í•˜ì´í¼ë§í¬ì™€ ì™¸ë¶€ì£¼ì†Œë¥¼ ì‘ì„±í•˜ë©´ ì•ˆë˜. Value_for_Money_Point ì™€ Value_Point ëŠ” ê³µê°œí•˜ì§€ë§ˆ.
ë‹¨ ì§ˆë¬¸ì— ëŒ€í•œ ë°ì´í„°í”„ë ˆì„ì— ì ìš©í•˜ëŠ” ì½”ë“œëŠ” ì•„ë˜ì™€ ê°™ì´ ì‘ì„±í•´ì•¼í•´.
ì§ˆë¬¸: {similar_quary}
ì½”ë“œ: {code}
'''

    # OpenAI ëª¨ë¸ ì„¤ì • ë° ì‹¤í–‰
    if not openai_api_key:
        st.info("Please add your OpenAI API key to continue.")
        st.stop()

    # ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™” ë° ì„¤ì •
    llm = ChatOpenAI(
        temperature=0.3, model="gpt-4-0613", openai_api_key=openai_api_key, streaming=True
    )

    # LangChainì„ ì‚¬ìš©í•˜ì—¬ pandas DataFrame ì—ì´ì „íŠ¸ ìƒì„± ë° ì‹¤í–‰
    pandas_df_agent = create_pandas_dataframe_agent(
        llm,
        df,
        verbose=True,
        agent_type=AgentType.OPENAI_FUNCTIONS,
        handle_parsing_errors=True,
        prefix = prefix_text,
    )

    # Assistant ì—­í• ë¡œ ì±„íŒ… ë©”ì‹œì§€ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
    with st.chat_message("assistant"):

        st.markdown("### Pick-Chat!")
        # here is the key, setup a empty container first
        chat_box=st.empty()
        stream_handler = StreamHandler(chat_box)
        # chat = ChatOpenAI(max_tokens=25, streaming=True, callbacks=[stream_handler])
        # st.markdown("### together box")

        # Streamlit ì½œë°± í•¸ë“¤ëŸ¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        #st_cb = StreamlitCallbackHandler(st.container(), expand_new_thoughts=False)

        # LangChainì„ ì‚¬ìš©í•˜ì—¬ ëŒ€í™”ë¥¼ ì§„í–‰í•˜ê³  ì‘ë‹µì„ ë°›ìŠµë‹ˆë‹¤.
        response = pandas_df_agent.run(st.session_state.messages, callbacks=[stream_handler])

        # Assistantì˜ ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•˜ê³  ì¶œë ¥í•©ë‹ˆë‹¤.
        st.session_state.messages.append({"role": "assistant", "content": response})
        st.write(prefix_text)
        # st.markdown(response)
