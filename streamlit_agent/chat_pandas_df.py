from langchain.agents import AgentType
from langchain_experimental.agents.agent_toolkits.pandas.base import create_pandas_dataframe_agent
#from langchain.callbacks import StreamlitCallbackHandler
from langchain.callbacks.base import BaseCallbackHandler
from langchain.chat_models import ChatOpenAI
#from langchain.schema import AIMessage, HumanMessage, SystemMessage

# from langchain.prompts.example_selector import SemanticSimilarityExampleSelector
# from langchain.vectorstores import FAISS
# from langchain.embeddings import OpenAIEmbeddings
# from langchain.prompts import FewShotPromptTemplate, PromptTemplate
# from langchain.llms import OpenAI

#from streamlit_chat import message
import streamlit as st
import pandas as pd
import os




# file_formats = {
#     "csv": pd.read_csv,
#     "xls": pd.read_excel,
#     "xlsx": pd.read_excel,
#     "xlsm": pd.read_excel,
#     "xlsb": pd.read_excel,
# }


from PIL import Image
im_logo = Image.open("ë¡œê³ .png")
im_symbol = Image.open("symbol.png")

# Submit ë²„íŠ¼ ìƒíƒœë¥¼ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
def clear_submit():
    st.session_state["submit"] = False




class StreamHandler(BaseCallbackHandler):
    def __init__(self, container, initial_text=""):
        self.container = container
        self.text=initial_text
    def on_llm_new_token(self, token: str, **kwargs) -> None:
        # "/" is a marker to show difference
        # you don't need it
        self.text+=token
        self.container.markdown(self.text)

# Streamlit í˜ì´ì§€ ì„¤ì •
def do_stuff_on_page_load():
    st.set_page_config(layout="wide", page_title="Pick-Chat! : Chat with DataFrame!", page_icon=im_symbol)#
do_stuff_on_page_load()
#st.set_page_config(layout="wide", page_title="Pick-Chat! : Chat with DataFrame!", page_icon=im_symbol)#
st.image(im_logo)
#st.title("Pick-Chat! : Chat with DataFrame!") #ğŸ¦œ 

hide_streamlit_style = """
            <style>
            #MainMenu {visibility: hidden;}
            footer {visibility: hidden;}
            header {visibility: hidden;}
            #.st-emotion-cache-18ni7ap {visibility: hidden;}
            .st-emotion-cache-1pxazr7 {visibility: hidden;}
            .st-emotion-cache-eczf16 {visibility: hidden;}
            a.viewerBadge_container__r5tak.styles_viewerBadge__CvC9N {visibility: hidden;}
            </style>
            """
#st.markdown(hide_streamlit_style, unsafe_allow_html=True)

@st.cache_data
def load_data(url):
    df = pd.read_excel(url)
    return df
df = load_data("laptop_sdf_231026.xlsx")
#df = df.astype(str)
df.pop('Unnamed: 0')
#df

#ì˜ˆ
examples = [
  {"input": "good_price", "output": "df_filtered = df[(df['Value_for_Money_Point'] >= df['Value_for_Money_Point'].quantile(0.75))]\ndf_sorted = df_filtered.groupby('Manufacturer').apply(lambda x: x.nlargest(1, 'Value_for_Money_Point')).reset_index(drop=True).sort_values(by='Price_won', ascending=True).head(5)"},
  {"input": "new&light", "output": "df_filtered = df[(df['CPU_Launch_Date'] >= 2023) & (df['inch_per_kg'] >= 13)]\ndf_sorted = df_filtered.groupby('Manufacturer').apply(lambda x: x.nlargest(1, 'Value_for_Money_Point')).reset_index(drop=True).sort_values(by='Price_won', ascending=True).head(5)"},
  {"input": "new&high_performance", "output": "df_filtered = df[(df['CPU_Launch_Date'] >= 2023) & (df['CPU_Score'] >= df['CPU_Score'].quantile(0.75)) & (df['GPU_Score'] >= df['GPU_Score'].quantile(0.75))]\ndf_sorted = df_filtered.groupby('Manufacturer').apply(lambda x: x.nlargest(1, 'Value_Point')).reset_index(drop=True).sort_values(by='Price_won', ascending=True).head(5)"},
  {"input": "new&good_display", "output": "df_filtered = df[(df['CPU_Launch_Date'] >= 2023) & (df['Display_Point'] >= df['Display_Point'].quantile(0.80))]\ndf_sorted = df_filtered.groupby('Manufacturer').apply(lambda x: x.nlargest(1, 'Value_for_Money_Point')).reset_index(drop=True).sort_values(by='Price_won', ascending=True).head(5)"},
  {"input": "new&good_service", "output": "df_filtered = df[(df['Manufacturer'].isin(['SAMSUNG', 'LG'])) & (df['CPU_Launch_Date'] >= 2023)]\ndf_sorted = df_filtered.sort_values(by=['Value_for_Money_Point', 'Price_won'], ascending=[False, True]).head(5)"},
  {"input": "light&high_performance", "output": "df_filtered = df[(df['inch_per_kg'] >= df['inch_per_kg'].quantile(0.74)) & (df['CPU_Score'] >= df['CPU_Score'].median()) & (df['GPU_Score'] >= df['GPU_Score'].median())]\ndf_sorted = df_filtered.groupby('Manufacturer').apply(lambda x: x.nlargest(1, 'Value_for_Money_Point')).reset_index(drop=True).sort_values(by='Price_won', ascending=True).head(5)"},
  {"input": "good_display&light", "output": "df_filtered = df[(df['Display_Point'] >= df['Display_Point'].quantile(0.85)) & (df['inch_per_kg'] >= df['inch_per_kg'].quantile(0.74))]\ndf_sorted = df_filtered.groupby('Manufacturer').apply(lambda x: x.nlargest(1, 'Value_for_Money_Point')).reset_index(drop=True).sort_values(by='Price_won', ascending=True).head(5)"},
  {"input": "light&good_service", "output": "df_filtered = df[df['Manufacturer'].isin(['SAMSUNG', 'LG']) & (df['inch_per_kg'] >= df['inch_per_kg'].quantile(0.74))]\ndf_sorted = df_sorted = df_filtered.groupby('Manufacturer').apply(lambda x: x.nlargest(3, 'Value_for_Money_Point')).reset_index(drop=True).sort_values(by='Price_won', ascending=True).head(5)"},
  {"input": "good_display&high_performance", "output": "df_filtered = df[(df['Display_Point'] >= df['Display_Point'].quantile(0.90)) & (df['CPU_Score'] >= df['CPU_Score'].quantile(0.90)) & (df['GPU_Score'] >= df['GPU_Score'].quantile(0.90))]\ndf_sorted = df_filtered.groupby('Manufacturer').apply(lambda x: x.nlargest(1, 'Value_Point')).reset_index(drop=True).sort_values(by='Price_won', ascending=True).head(5)"},
  {"input": "good_service&high_performance", "output": "df_filtered = df[df['Manufacturer'].isin(['SAMSUNG', 'LG']) & (df['CPU_Score'] >= 20000)]\ndf_sorted = df_filtered.sort_values(by=['Value_Point', 'Price_won'], ascending=[False, True]).head(5)"},
  {"input": "good_display&good_service", "output": "df_filtered = df[(df['Manufacturer'].isin(['SAMSUNG', 'LG'])) & (df['Display_Point'] >= df['Display_Point'].quantile(0.75))]\ndf_sorted = df_filtered.sort_values(by=['Value_for_Money_Point', 'Price_won'], ascending=[False, True]).head(5)"}
]

prefix_text = f'''ë„ˆëŠ” ë…¸íŠ¸ë¶ì„ ì „ë¬¸ì ìœ¼ë¡œ ì¶”ì²œí•´ì£¼ëŠ” ì±—ë´‡ Pick-Chat!ì´ì•¼.
ê°€ê²©ê³¼ ë¬´ê²Œì™€ í™”ë©´í¬ê¸°ì™€ ì¶”ì²œì´ìœ ë¥¼ ë§í•´ì¤˜. ë‹¤ë¥¸ ì •ë³´ëŠ” ìš”ì²­ì‹œì—ë§Œ ì œê³µí•´.
ì„œë¡œë‹¤ë¥¸ì œì¡°ì‚¬ë¡œ ì œí’ˆì„ ìµœëŒ€ 5ê°œ ì¶”ì²œí•˜ê³  ì œí’ˆë§ˆë‹¤ ì¤„ë°”ê¿ˆì„ í•´ì¤˜.
ì§ˆë¬¸ì— ë¶€í•©í•˜ëŠ” ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°ì—ëŠ” ì‚¬ìš©ìì—ê²Œ ì§ˆë¬¸ì„ ë” ìì„¸íˆ ì‘ì„±í•´ë‹¬ë¼ê³  ìš”ì²­í•´.
í•œê¸€ë¡œ ë‹µë³€ì„ ì‘ì„±í•´. í•˜ì´í¼ë§í¬ì™€ ì™¸ë¶€ì£¼ì†Œë¥¼ ì‘ì„±í•˜ë©´ ì•ˆë˜. Display_Point, Value_for_Money_Point, Value_Point ëŠ” ê³µê°œí•˜ì§€ë§ˆ.
ë‹¨ ì§ˆë¬¸ì— ëŒ€í•œ ë°ì´í„°í”„ë ˆì„ì— ì ìš©í•˜ëŠ” ì½”ë“œëŠ” ì•„ë˜ì™€ ê°™ì´ ì‘ì„±í•´ì•¼í•´
{examples}
'''
   
# # SemanticSimilarityExampleSelectorëŠ” ì˜ë¯¸ë¡ ì  ì˜ë¯¸ì— ë”°ë¼ ì…ë ¥ê³¼ ìœ ì‚¬í•œ ì˜ˆì œë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
# example_selector = SemanticSimilarityExampleSelector.from_examples(
#   examples,
#   OpenAIEmbeddings(openai_api_key=openai_api_key),  # ì˜ë¯¸ì  ìœ ì‚¬ì„±ì„ ì¸¡ì •í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ì„ë² ë”©ì„ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ì„ë² ë”© í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
#   FAISS,  # ì„ë² ë”©ì„ ì €ì¥í•˜ê³  ìœ ì‚¬ì„± ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” VectorStore í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
#   k=1 # ìƒì„±í•  ì˜ˆì œ ê°œìˆ˜ì…ë‹ˆë‹¤.
# )

# similar_prompt = FewShotPromptTemplate(
#   example_selector=example_selector,  # ì˜ˆì œ ì„ íƒì— ë„ì›€ì´ ë˜ëŠ” ê°œì²´
#   example_prompt=example_prompt,  # í”„ë¡¬í”„íŠ¸
#   prefix=prefix_text,  # í”„ë¡¬í”„íŠ¸ì˜ ìƒë‹¨ê³¼ í•˜ë‹¨ì— ì¶”ê°€ë˜ëŠ” ì‚¬ìš©ì ì§€ì • ì‚¬í•­
#   suffix="Input: {noun}\nOutput:",
#   input_variables=["noun"],  # í”„ë¡¬í”„íŠ¸ê°€ ìˆ˜ì‹ í•  ì…ë ¥ í•­ëª©
# )

# similar_prompt.format(noun=input('')


# OpenAI API í‚¤ ì…ë ¥ì„ ë°›ìŠµë‹ˆë‹¤.
openai_api_key = st.secrets["openai_key"]

# ëŒ€í™” ê¸°ë¡ì„ ì´ˆê¸°í™”í•˜ê±°ë‚˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ëŒ€í™” ê¸°ë¡ì„ ì‚­ì œí•©ë‹ˆë‹¤.
intro = f'{len(df)}ê°œì˜ ë…¸íŠ¸ë¶ì´ ìˆì–´ìš”! ì§ˆë¬¸ì„ ìƒì„¸íˆ ì‘ì„±í•´ ì£¼ì‹œë©´ ì•Œë§ëŠ” ì œí’ˆì„ ì°¾ì•„ë“œë¦´ê²Œìš”!'
if "messages" not in st.session_state or st.button("Clear conversation history"):# 
    # ì´ˆê¸° ëŒ€í™” ë©”ì‹œì§€ ì„¤ì •
    st.session_state["messages"] = [{"role": "assistant", "content": intro }]

# ì´ì „ ëŒ€í™” ë‚´ìš©ì„ í‘œì‹œí•©ë‹ˆë‹¤.
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
if prompt := st.chat_input(placeholder="ê°€ë³ê³  ë¹ ë¥¸ ë…¸íŠ¸ë¶ ì¶”ì²œí•´ì¤„ë˜? ë¬´ê²ŒëŠ” 1.5kg ì´í•˜ë©´ ì¢‹ì•„!"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
     
    # OpenAI ëª¨ë¸ ì„¤ì • ë° ì‹¤í–‰
    if not openai_api_key:
        st.info("Please add your OpenAI API key to continue.")
        st.stop()

    # ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™” ë° ì„¤ì •
    llm = ChatOpenAI(
        temperature=0.25, model="gpt-4", openai_api_key=openai_api_key, streaming=True
    )

    # LangChainì„ ì‚¬ìš©í•˜ì—¬ pandas DataFrame ì—ì´ì „íŠ¸ ìƒì„± ë° ì‹¤í–‰
    pandas_df_agent = create_pandas_dataframe_agent(
        llm,
        df,
        verbose=False,
        agent_type=AgentType.OPENAI_FUNCTIONS,
        handle_parsing_errors=True,
        prefix = prefix_text,
    )

    # Assistant ì—­í• ë¡œ ì±„íŒ… ë©”ì‹œì§€ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
    with st.chat_message("assistant"):

        st.markdown("### Pick-Chat!")
        # here is the key, setup a empty container first
        chat_box=st.empty()
        stream_handler = StreamHandler(chat_box)
        # chat = ChatOpenAI(max_tokens=25, streaming=True, callbacks=[stream_handler])
        # st.markdown("### together box")

        # Streamlit ì½œë°± í•¸ë“¤ëŸ¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        #st_cb = StreamlitCallbackHandler(st.container(), expand_new_thoughts=False)

        # LangChainì„ ì‚¬ìš©í•˜ì—¬ ëŒ€í™”ë¥¼ ì§„í–‰í•˜ê³  ì‘ë‹µì„ ë°›ìŠµë‹ˆë‹¤.
        response = pandas_df_agent.run(st.session_state.messages, callbacks=[stream_handler])

        # Assistantì˜ ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•˜ê³  ì¶œë ¥í•©ë‹ˆë‹¤.
        st.session_state.messages.append({"role": "assistant", "content": response})
        #st.write(response)
        # st.markdown(response)


