from langchain.agents import AgentType
from langchain.agents import create_pandas_dataframe_agent
from langchain.callbacks import StreamlitCallbackHandler
from langchain.callbacks.base import BaseCallbackHandler
from langchain.chat_models import ChatOpenAI
from langchain.schema import AIMessage, HumanMessage, SystemMessage
from streamlit_chat import message

import streamlit as st
import pandas as pd
import os

df = pd.read_csv("/content/laptop_sdf_231013.csv")
#df = df.astype(str)
df.pop('Unnamed: 0')
#df

file_formats = {
    "csv": pd.read_csv,
    "xls": pd.read_excel,
    "xlsx": pd.read_excel,
    "xlsm": pd.read_excel,
    "xlsb": pd.read_excel,
}


prefix_text = '''ë„ˆëŠ” ë…¸íŠ¸ë¶ì„ ì „ë¬¸ì ìœ¼ë¡œ ì¶”ì²œí•´ì£¼ëŠ” ì±—ë´‡ Pick-Chat!ì´ì•¼.
í•­ìƒ ê°€ê²©ê³¼ ì¶”ì²œê·¼ê±°ë¥¼ ê°„ëµíˆ ì œê³µí•´. ì œí’ˆë§ˆë‹¤ ì¤„ë°”ê¿ˆì„ í•´ì¤˜.
ì§ˆë¬¸ì— ë¶€í•©í•˜ëŠ” ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°ì—ëŠ” ì‚¬ìš©ìì—ê²Œ ì§ˆë¬¸ì„ ë” ìì„¸íˆ ì‘ì„±í•´ë‹¬ë¼ê³  ìš”ì²­í•´.
í•­ìƒ í•œê¸€ë¡œ ë‹µë³€ì„ ì‘ì„±í•´. ì™¸ë¶€ë§í¬ë¥¼ ì‘ì„±í•˜ë©´ ì•ˆë˜.
ë‹¨ ì§ˆë¬¸ì— ëŒ€í•œ ë°ì´í„°í”„ë ˆì„ì— ì ìš©í•˜ëŠ” ì½”ë“œëŠ” ì•„ë˜ì™€ ê°™ì´ ì‘ì„±í•´ì•¼í•´.
ì§ˆë¬¸: í™”ë©´ì¢‹ê³  ë¹ ë¥´ê³  ê°€ë²¼ìš´ ë…¸íŠ¸ë¶ ê³¨ë¼ì¤˜
ì½”ë“œ: df['Gram_per_Inch'] = (df['ë¬´ê²Œ(kg)'] / df['inch'])*1000
df_filtered = df[(df['ppi'] > df['ppi'].median()) & (df['Screen_Brightness'] > df['Screen_Brightness'].median()) & (df['CPU_Score'] > df['CPU_Score'].median()) & df['Gram_per_Inch'] < df['Gram_per_Inch'].median())]
df_sorted = df_filtered.groupby('Manufacturer').apply(lambda x: x.nlargest(1, 'Value_for_Money_Point')).reset_index(drop=True).sort_values(by='Price_won', ascending=True)
df_sorted.head(5)
ì§ˆë¬¸: ì•„ì£¼ ê°€ë³ê³  ê°€ì„±ë¹„ ì¢‹ì€ ê±¸ë¡œ ê³¨ë¼ì¤˜
ì½”ë“œ: df['Gram_per_Inch'] = (df['ë¬´ê²Œ(kg)'] / df['inch'])*1000
df_filtered = df[(df['Gram_per_Inch'] < df['Gram_per_Inch'].quantile(0.25)) & df['Value_for_Money_Point'] > df['Value_for_Money_Point'].median())]
df_sorted = df_filtered.groupby('Manufacturer').apply(lambda x: x.nlargest(1, 'Value_for_Money_Point')).reset_index(drop=True).sort_values(by='Price_won', ascending=True)
df_sorted.head(5)
ì§ˆë¬¸: ê°€ë³ê³  ì„±ëŠ¥ì´ ì•„ì£¼ ë›°ì–´ë‚œê±¸ë¡œ ë¶€íƒí•´
ì½”ë“œ: df['Gram_per_Inch'] = (df['ë¬´ê²Œ(kg)'] / df['inch'])*1000
df_filtered = df['Gram_per_Inch'] < df['Gram_per_Inch'].median()) & (df['CPU_Score'] > df['CPU_Score'].quantile(0.75)) & (df['GPU_Score'] > df['GPU_Score'].quantile(0.75))]
df_sorted = df_filtered.groupby('Manufacturer').apply(lambda x: x.nlargest(1, 'Value_Point')).reset_index(drop=True).sort_values(by='Price_won', ascending=True)
df_sorted.head(5)
'''

# Submit ë²„íŠ¼ ìƒíƒœë¥¼ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
def clear_submit():
    st.session_state["submit"] = False

# ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. (ìºì‹± ì„¤ì •: 2ì‹œê°„)
@st.cache_data(ttl="2h")
def load_data(uploaded_file):
    try:
        # íŒŒì¼ í™•ì¥ì ì¶”ì¶œ
        ext = os.path.splitext(uploaded_file.name)[1][1:].lower()
    except:
        ext = uploaded_file.split(".")[-1]

    # íŒŒì¼ í˜•ì‹ì— ë”°ë¼ ì ì ˆí•œ í•¨ìˆ˜ë¡œ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    if ext in file_formats:
        return file_formats[ext](uploaded_file)
    else:
        # ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì¼ ê²½ìš° ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥
        st.error(f"Unsupported file format: {ext}")
        return None

class StreamHandler(BaseCallbackHandler):
    def __init__(self, container, initial_text=""):
        self.container = container
        self.text=initial_text
    def on_llm_new_token(self, token: str, **kwargs) -> None:
        # "/" is a marker to show difference
        # you don't need it
        self.text+=token
        self.container.markdown(self.text)

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="LangChain: Chat with pandas DataFrame", page_icon="ğŸ¦œ")
st.title("ğŸ¦œ LangChain: Chat with pandas DataFrame")

# # íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯ì„ ìƒì„±í•©ë‹ˆë‹¤.
# uploaded_file = st.file_uploader(
#     "Upload a Data file",
#     type=list(file_formats.keys()),
#     help="Various File formats are Support",
#     on_change=clear_submit,
# )

# # íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ì„ ë•Œ ê²½ê³  ë©”ì‹œì§€ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
# if not uploaded_file:
#     st.warning(
#         "This app uses LangChain's `PythonAstREPLTool` which is vulnerable to arbitrary code execution. Please use caution in deploying and sharing this app."
#     )

# # íŒŒì¼ì´ ì—…ë¡œë“œëœ ê²½ìš° ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
# if uploaded_file:
#     df = load_data(uploaded_file)

# OpenAI API í‚¤ ì…ë ¥ì„ ë°›ìŠµë‹ˆë‹¤.
openai_api_key = st.sidebar.text_input("OpenAI API Key", type="password")

# ëŒ€í™” ê¸°ë¡ì„ ì´ˆê¸°í™”í•˜ê±°ë‚˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ëŒ€í™” ê¸°ë¡ì„ ì‚­ì œí•©ë‹ˆë‹¤.
if "messages" not in st.session_state or st.sidebar.button("Clear conversation history"):
    # ì´ˆê¸° ëŒ€í™” ë©”ì‹œì§€ ì„¤ì •
    st.session_state["messages"] = [{"role": "assistant", "content": "ì§ˆë¬¸ì„ ìƒì„¸íˆ ì‘ì„±í•´ ì£¼ì‹œë©´ ì •í™•í•œ ë‹µë³€ì´ ê°€ëŠ¥í•´ìš”!"}]

# ì´ì „ ëŒ€í™” ë‚´ìš©ì„ í‘œì‹œí•©ë‹ˆë‹¤.
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
if prompt := st.chat_input(placeholder="ê°€ë³ê³  ë¹ ë¥¸ ë…¸íŠ¸ë¶ ì¶”ì²œí•´ì¤„ë˜? ë¬´ê²ŒëŠ” 1.5kg ì´í•˜ë©´ ê´œì°®ì„ê±° ê°™ì•„!"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    # OpenAI ëª¨ë¸ ì„¤ì • ë° ì‹¤í–‰
    if not openai_api_key:
        st.info("Please add your OpenAI API key to continue.")
        st.stop()

    # ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™” ë° ì„¤ì •
    llm = ChatOpenAI(
        temperature=0, model="gpt-4-0613", openai_api_key=openai_api_key, streaming=True
    )

    # LangChainì„ ì‚¬ìš©í•˜ì—¬ pandas DataFrame ì—ì´ì „íŠ¸ ìƒì„± ë° ì‹¤í–‰
    pandas_df_agent = create_pandas_dataframe_agent(
        llm,
        df,
        verbose=False,
        agent_type=AgentType.OPENAI_FUNCTIONS,
        handle_parsing_errors=True,
        prefix = prefix_text,
    )

    # Assistant ì—­í• ë¡œ ì±„íŒ… ë©”ì‹œì§€ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
    with st.chat_message("assistant"):

        st.markdown("### Pick-Chat!")
        # here is the key, setup a empty container first
        chat_box=st.empty()
        stream_handler = StreamHandler(chat_box)
        # chat = ChatOpenAI(max_tokens=25, streaming=True, callbacks=[stream_handler])
        # st.markdown("### together box")

        # Streamlit ì½œë°± í•¸ë“¤ëŸ¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        # st_cb = StreamlitCallbackHandler(st.container(), expand_new_thoughts=False)

        # LangChainì„ ì‚¬ìš©í•˜ì—¬ ëŒ€í™”ë¥¼ ì§„í–‰í•˜ê³  ì‘ë‹µì„ ë°›ìŠµë‹ˆë‹¤.
        response = pandas_df_agent.run(st.session_state.messages, callbacks=[stream_handler])

        # Assistantì˜ ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•˜ê³  ì¶œë ¥í•©ë‹ˆë‹¤.
        st.session_state.messages.append({"role": "assistant", "content": response})
        # st.write(response)
        # st.markdown(response)
